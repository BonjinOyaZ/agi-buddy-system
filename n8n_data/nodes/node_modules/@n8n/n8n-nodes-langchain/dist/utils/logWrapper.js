"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.logWrapper = exports.callMethodSync = exports.callMethodAsync = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const tools_1 = require("langchain/tools");
const schema_1 = require("langchain/schema");
const base_1 = require("langchain/chat_models/base");
const base_2 = require("langchain/embeddings/base");
const base_3 = require("langchain/vectorstores/base");
const text_splitter_1 = require("langchain/text_splitter");
const base_4 = require("langchain/llms/base");
const memory_1 = require("langchain/memory");
const retriever_1 = require("langchain/schema/retriever");
const output_parser_1 = require("langchain/schema/output_parser");
const lodash_1 = require("lodash");
const N8nJsonLoader_1 = require("./N8nJsonLoader");
const N8nBinaryLoader_1 = require("./N8nBinaryLoader");
async function callMethodAsync(parameters) {
    try {
        return await parameters.method.call(this, ...parameters.arguments);
    }
    catch (e) {
        const connectedNode = parameters.executeFunctions.getNode();
        const error = new n8n_workflow_1.NodeOperationError(connectedNode, e);
        parameters.executeFunctions.addOutputData(parameters.connectionType, parameters.currentNodeRunIndex, error);
        throw new n8n_workflow_1.NodeOperationError(connectedNode, `Error on node "${connectedNode.name}" which is connected via input "${parameters.connectionType}"`);
    }
}
exports.callMethodAsync = callMethodAsync;
function callMethodSync(parameters) {
    try {
        return parameters.method.call(this, ...parameters.arguments);
    }
    catch (e) {
        const connectedNode = parameters.executeFunctions.getNode();
        const error = new n8n_workflow_1.NodeOperationError(connectedNode, e);
        parameters.executeFunctions.addOutputData(parameters.connectionType, parameters.currentNodeRunIndex, error);
        throw new n8n_workflow_1.NodeOperationError(connectedNode, `Error on node "${connectedNode.name}" which is connected via input "${parameters.connectionType}"`);
    }
}
exports.callMethodSync = callMethodSync;
function logWrapper(originalInstance, executeFunctions) {
    return new Proxy(originalInstance, {
        get: (target, prop) => {
            let connectionType;
            if (originalInstance instanceof memory_1.BaseChatMemory) {
                if (prop === 'loadMemoryVariables' && 'loadMemoryVariables' in target) {
                    return async (values) => {
                        connectionType = "ai_memory";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { action: 'loadMemoryVariables', values } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [values],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { action: 'loadMemoryVariables', response } }],
                        ]);
                        return response;
                    };
                }
                else if (prop === 'outputKey' &&
                    'outputKey' in target &&
                    target.constructor.name === 'BufferWindowMemory') {
                    connectionType = "ai_memory";
                    const { index } = executeFunctions.addInputData(connectionType, [
                        [{ json: { action: 'chatHistory' } }],
                    ]);
                    const response = target[prop];
                    target.chatHistory
                        .getMessages()
                        .then((messages) => {
                        executeFunctions.addOutputData("ai_memory", index, [
                            [{ json: { action: 'chatHistory', chatHistory: messages } }],
                        ]);
                    })
                        .catch((error) => {
                        executeFunctions.addOutputData("ai_memory", index, [
                            [{ json: { action: 'chatHistory', error } }],
                        ]);
                    });
                    return response;
                }
            }
            if (originalInstance instanceof schema_1.BaseChatMessageHistory) {
                if (prop === 'getMessages' && 'getMessages' in target) {
                    return async () => {
                        connectionType = "ai_memory";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { action: 'getMessages' } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { action: 'getMessages', response } }],
                        ]);
                        return response;
                    };
                }
                else if (prop === 'addMessage' && 'addMessage' in target) {
                    return async (message) => {
                        connectionType = "ai_memory";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { action: 'addMessage', message } }],
                        ]);
                        await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [message],
                        });
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { action: 'addMessage' } }],
                        ]);
                    };
                }
            }
            if (originalInstance instanceof base_4.BaseLLM || originalInstance instanceof base_1.BaseChatModel) {
                if (prop === '_generate' && '_generate' in target) {
                    return async (messages, options, runManager) => {
                        connectionType = "ai_languageModel";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { messages, options } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [messages, options, runManager],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof output_parser_1.BaseOutputParser) {
                if (prop === 'getFormatInstructions' && 'getFormatInstructions' in target) {
                    return (options) => {
                        connectionType = "ai_outputParser";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { action: 'getFormatInstructions' } }],
                        ]);
                        const response = callMethodSync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [options],
                        });
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { action: 'getFormatInstructions', response } }],
                        ]);
                        return response;
                    };
                }
                else if (prop === 'parse' && 'parse' in target) {
                    return async (text) => {
                        connectionType = "ai_outputParser";
                        const stringifiedText = (0, lodash_1.isObject)(text) ? JSON.stringify(text) : text;
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { action: 'parse', text: stringifiedText } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [stringifiedText],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { action: 'parse', response } }],
                        ]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof retriever_1.BaseRetriever) {
                if (prop === 'getRelevantDocuments' && 'getRelevantDocuments' in target) {
                    return async (query, config) => {
                        connectionType = "ai_retriever";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { query, config } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [query, config],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof base_2.Embeddings) {
                if (prop === 'embedDocuments' && 'embedDocuments' in target) {
                    return async (documents) => {
                        connectionType = "ai_embedding";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { documents } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [documents],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
                if (prop === 'embedQuery' && 'embedQuery' in target) {
                    return async (query) => {
                        connectionType = "ai_embedding";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { query } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [query],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof N8nJsonLoader_1.N8nJsonLoader ||
                originalInstance instanceof N8nBinaryLoader_1.N8nBinaryLoader) {
                if (prop === 'processAll' && 'processAll' in target) {
                    return async (items) => {
                        connectionType = "ai_document";
                        const { index } = executeFunctions.addInputData(connectionType, [items]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [items],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
                if (prop === 'processItem' && 'processItem' in target) {
                    return async (item, itemIndex) => {
                        connectionType = "ai_document";
                        const { index } = executeFunctions.addInputData(connectionType, [[item]]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [item, itemIndex],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [
                            [{ json: { response }, pairedItem: { item: itemIndex } }],
                        ]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof text_splitter_1.TextSplitter) {
                if (prop === 'splitText' && 'splitText' in target) {
                    return async (text) => {
                        connectionType = "ai_textSplitter";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { textSplitter: text } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [text],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof tools_1.Tool) {
                if (prop === '_call' && '_call' in target) {
                    return async (query) => {
                        connectionType = "ai_tool";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { query } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [query],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            if (originalInstance instanceof base_3.VectorStore) {
                if (prop === 'similaritySearch' && 'similaritySearch' in target) {
                    return async (query, k, filter, _callbacks) => {
                        connectionType = "ai_vectorStore";
                        const { index } = executeFunctions.addInputData(connectionType, [
                            [{ json: { query, k, filter } }],
                        ]);
                        const response = (await callMethodAsync.call(target, {
                            executeFunctions,
                            connectionType,
                            currentNodeRunIndex: index,
                            method: target[prop],
                            arguments: [query, k, filter, _callbacks],
                        }));
                        executeFunctions.addOutputData(connectionType, index, [[{ json: { response } }]]);
                        return response;
                    };
                }
            }
            return target[prop];
        },
    });
}
exports.logWrapper = logWrapper;
//# sourceMappingURL=logWrapper.js.map