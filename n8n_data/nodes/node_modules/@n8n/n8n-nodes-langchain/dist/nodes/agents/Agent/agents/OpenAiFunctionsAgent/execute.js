"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.openAiFunctionsAgentExecute = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const agents_1 = require("langchain/agents");
const prompts_1 = require("langchain/prompts");
const output_parsers_1 = require("langchain/output_parsers");
const memory_1 = require("langchain/memory");
const openai_1 = require("langchain/chat_models/openai");
async function openAiFunctionsAgentExecute() {
    var _a;
    this.logger.verbose('Executing OpenAi Functions Agent');
    const model = (await this.getInputConnectionData("ai_languageModel", 0));
    if (!(model instanceof openai_1.ChatOpenAI)) {
        throw new n8n_workflow_1.NodeOperationError(this.getNode(), 'OpenAI Functions Agent requires OpenAI Chat Model');
    }
    const memory = (await this.getInputConnectionData("ai_memory", 0));
    const tools = (await this.getInputConnectionData("ai_tool", 0));
    const outputParsers = (await this.getInputConnectionData("ai_outputParser", 0));
    const options = this.getNodeParameter('options', 0, {});
    const agentConfig = {
        tags: ['openai-functions'],
        agent: agents_1.OpenAIAgent.fromLLMAndTools(model, tools, {
            prefix: options.systemMessage,
        }),
        tools,
        maxIterations: (_a = options.maxIterations) !== null && _a !== void 0 ? _a : 10,
        memory: memory !== null && memory !== void 0 ? memory : new memory_1.BufferMemory({
            returnMessages: true,
            memoryKey: 'chat_history',
            inputKey: 'input',
            outputKey: 'output',
        }),
    };
    const agentExecutor = agents_1.AgentExecutor.fromAgentAndTools(agentConfig);
    const returnData = [];
    let outputParser;
    let prompt;
    if (outputParsers.length) {
        outputParser =
            outputParsers.length === 1 ? outputParsers[0] : new output_parsers_1.CombiningOutputParser(...outputParsers);
        const formatInstructions = outputParser.getFormatInstructions();
        prompt = new prompts_1.PromptTemplate({
            template: '{input}\n{formatInstructions}',
            inputVariables: ['input'],
            partialVariables: { formatInstructions },
        });
    }
    const items = this.getInputData();
    for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
        let input = this.getNodeParameter('text', itemIndex);
        if (input === undefined) {
            throw new n8n_workflow_1.NodeOperationError(this.getNode(), 'No value for the required parameter "Text" was returned.');
        }
        if (prompt) {
            input = (await prompt.invoke({ input })).value;
        }
        let response = await agentExecutor.call({ input, outputParsers });
        if (outputParser) {
            response = { output: await outputParser.parse(response.output) };
        }
        returnData.push({ json: response });
    }
    return this.prepareOutputData(returnData);
}
exports.openAiFunctionsAgentExecute = openAiFunctionsAgentExecute;
//# sourceMappingURL=execute.js.map