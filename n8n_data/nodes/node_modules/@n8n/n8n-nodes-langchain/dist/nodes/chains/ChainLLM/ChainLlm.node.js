"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ChainLlm = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const prompts_1 = require("langchain/prompts");
const output_parsers_1 = require("langchain/output_parsers");
const chains_1 = require("langchain/chains");
const base_1 = require("langchain/chat_models/base");
function getChainPromptTemplate(llm, messages, formatInstructions) {
    const queryTemplate = new prompts_1.PromptTemplate({
        template: `{query}${formatInstructions ? '\n{formatInstructions}' : ''}`,
        inputVariables: ['query'],
        partialVariables: formatInstructions ? { formatInstructions } : undefined,
    });
    if (llm instanceof base_1.BaseChatModel) {
        const parsedMessages = (messages !== null && messages !== void 0 ? messages : []).map((message) => {
            const messageClass = [
                prompts_1.SystemMessagePromptTemplate,
                prompts_1.AIMessagePromptTemplate,
                prompts_1.HumanMessagePromptTemplate,
            ].find((m) => m.lc_name() === message.type);
            if (!messageClass) {
                throw new Error(`Invalid message type "${message.type}"`);
            }
            return messageClass.fromTemplate(message.message);
        });
        parsedMessages.push(new prompts_1.HumanMessagePromptTemplate(queryTemplate));
        return prompts_1.ChatPromptTemplate.fromMessages(parsedMessages);
    }
    return queryTemplate;
}
async function createSimpleLLMChain(llm, query, prompt) {
    const chain = new chains_1.LLMChain({
        llm,
        prompt,
    });
    const response = (await chain.call({ query }));
    return Array.isArray(response) ? response : [response];
}
async function getChain(context, query, messages) {
    const llm = (await context.getInputConnectionData("ai_languageModel", 0));
    const outputParsers = (await context.getInputConnectionData("ai_outputParser", 0));
    const chatTemplate = getChainPromptTemplate(llm, messages);
    if (!outputParsers.length) {
        return createSimpleLLMChain(llm, query, chatTemplate);
    }
    const combinedOutputParser = outputParsers.length === 1 ? outputParsers[0] : new output_parsers_1.CombiningOutputParser(...outputParsers);
    const formatInstructions = combinedOutputParser.getFormatInstructions();
    const prompt = getChainPromptTemplate(llm, messages, formatInstructions);
    const chain = prompt.pipe(llm).pipe(combinedOutputParser);
    const response = (await chain.invoke({ query }));
    return Array.isArray(response) ? response : [response];
}
class ChainLlm {
    constructor() {
        this.description = {
            displayName: 'Basic LLM Chain',
            name: 'chainLlm',
            icon: 'fa:link',
            group: ['transform'],
            version: 1,
            description: 'A simple chain to prompt a large language mode',
            defaults: {
                name: 'Basic LLM Chain',
                color: '#909298',
            },
            codex: {
                alias: ['LangChain'],
                categories: ['AI'],
                subcategories: {
                    AI: ['Chains'],
                },
                resources: {
                    primaryDocumentation: [
                        {
                            url: 'https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/',
                        },
                    ],
                },
            },
            inputs: [
                "main",
                {
                    displayName: 'Model',
                    maxConnections: 1,
                    type: "ai_languageModel",
                    required: true,
                },
                {
                    displayName: 'Output Parser',
                    type: "ai_outputParser",
                    required: false,
                },
            ],
            outputs: ["main"],
            credentials: [],
            properties: [
                {
                    displayName: 'Prompt',
                    name: 'prompt',
                    type: 'string',
                    required: true,
                    default: '={{ $json.input }}',
                },
                {
                    displayName: 'The options below to add prompts are only valid for chat models, they will be ignored for other models.',
                    name: 'notice',
                    type: 'notice',
                    default: '',
                },
                {
                    displayName: 'Chat Messages',
                    name: 'messages',
                    type: 'fixedCollection',
                    typeOptions: {
                        multipleValues: true,
                    },
                    default: {},
                    placeholder: 'Add prompt',
                    options: [
                        {
                            name: 'messageValues',
                            displayName: 'Prompt',
                            values: [
                                {
                                    displayName: 'Type Name or ID',
                                    name: 'type',
                                    type: 'options',
                                    options: [
                                        {
                                            name: 'AI',
                                            value: prompts_1.AIMessagePromptTemplate.lc_name(),
                                        },
                                        {
                                            name: 'System',
                                            value: prompts_1.SystemMessagePromptTemplate.lc_name(),
                                        },
                                        {
                                            name: 'User',
                                            value: prompts_1.HumanMessagePromptTemplate.lc_name(),
                                        },
                                    ],
                                    default: prompts_1.SystemMessagePromptTemplate.lc_name(),
                                },
                                {
                                    displayName: 'Message',
                                    name: 'message',
                                    type: 'string',
                                    required: true,
                                    default: '',
                                },
                            ],
                        },
                    ],
                },
            ],
        };
    }
    async execute() {
        this.logger.verbose('Executing LLM Chain');
        const items = this.getInputData();
        const returnData = [];
        for (let i = 0; i < items.length; i++) {
            const prompt = this.getNodeParameter('prompt', i);
            const messages = this.getNodeParameter('messages.messageValues', i, []);
            if (prompt === undefined) {
                throw new n8n_workflow_1.NodeOperationError(this.getNode(), 'No value for the required parameter "Prompt" was returned.');
            }
            const responses = await getChain(this, prompt, messages);
            responses.forEach((response) => {
                let data;
                if (typeof response === 'string') {
                    data = {
                        response: {
                            text: response.trim(),
                        },
                    };
                }
                else if (Array.isArray(response)) {
                    data = {
                        data: response,
                    };
                }
                else if (response instanceof Object) {
                    data = response;
                }
                else {
                    data = {
                        response: {
                            text: response,
                        },
                    };
                }
                returnData.push({
                    json: data,
                });
            });
        }
        return [returnData];
    }
}
exports.ChainLlm = ChainLlm;
//# sourceMappingURL=ChainLlm.node.js.map